{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do some Bayesian flaring analysis!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get likelihood functions, prior distributions\n",
    "from siberianpine.bayes import calculate_joint_posterior_distribution, uninformative_prior, gaussian_prior\n",
    "\n",
    "# get the analysis toolkit\n",
    "from siberianpine.bayes import BayesianFlaringAnalysis\n",
    "\n",
    "# get the utils\n",
    "from siberianpine.utils import generate_random_power_law_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce some fake data to work with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time related stuff:\n",
    "\n",
    "Tprime = 50 #total observation time in days, must be int\n",
    "cadence = 4 #observations per hour\n",
    "obstimes = np.linspace(3000,3000+Tprime,Tprime*24*cadence) # 15 min cadence observations\n",
    "flaresperday = 10. # average flaring rate in flares per day\n",
    "\n",
    "times = obstimes[np.where(np.random.poisson(lam=1. / 24. / cadence * flaresperday,\n",
    "                                            size=Tprime * 24 * cadence))[0]]\n",
    "Mprime = len(times) # number of events\n",
    "\n",
    "#energy related stuff\n",
    "\n",
    "alpha_prior = 1.8 # fix power law exponent for now\n",
    "# Generate power law distributed data:\n",
    "events = generate_random_power_law_distribution(1, 1000, -alpha_prior + 1., size=Mprime, seed=15800)\n",
    "threshed = 1 # detection sensitivity limit\n",
    "\n",
    "#Choose your options\n",
    "\n",
    "mined = 100 # min ED value we want to predict a rate for (same as S2 in Wheatland 2004 paper)\n",
    "deltaT = 1. # predict rate of flares above threshold for deltaT days in the futures\n",
    "\n",
    "# determine a starting point for the MCMC sampling\n",
    "rate_prior = (flaresperday / np.abs(alpha_prior - 1.) *\n",
    "              np.power(mined, -alpha_prior +1.)) # evaluate cumulative FFD fit at mined\n",
    "eps_prior = 1 - np.exp(-rate_prior * deltaT) #use Poisson process statistics do get a probability from the rate\n",
    "\n",
    "# For an uninfromative prior on alpha we expect the MCMC result to be:\n",
    "alpha_prior = Mprime / np.sum(np.log(events/threshed)) + 1.\n",
    "\n",
    "# determine a starting point for the MCMC sampling\n",
    "rate_prior = (flaresperday / np.abs(alpha_prior - 1.) *\n",
    "              np.power(mined, -alpha_prior +1.)) # evaluate cumulative FFD fit at mined\n",
    "eps_prior = 1 - np.exp(-rate_prior * deltaT) #use Poisson process statistics do get a probability from the rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define a likelihood function and go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix and match priors into your final posterior\n",
    "def loglikelihood(theta, *args):\n",
    "    '''Custom likelihood to pass to BayesianFlaringAnalysis'''\n",
    "    def prior(x):\n",
    "        return gaussian_prior(x, 1.95, 2.05)\n",
    "    for beta in theta[:-1]:\n",
    "        posterior += calculate_joint_posterior_distribution([beta, theta[-1]], *args, prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize with all the relevant parameters:\n",
    "BFA = BayesianFlaringAnalysis(mined=mined, Tprime=Tprime, deltaT=deltaT, alpha_prior=alpha_prior, eps_prior=eps_prior,\n",
    "                              threshed=threshed, Mprime=Mprime, M=Mprime, events=events, loglikelihood=loglikelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run MCMC to sample the posterior distribution\n",
    "BFA.sample_posterior_with_mcmc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the samples and show if there is any covariance\n",
    "fig = BFA.show_corner_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the distributions are not quite symmetric instead of median and std we calculate 16, 50, 84 percentiles\n",
    "BFA.calculate_percentiles() # the first one is for eps, the second for alpha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "siberianpineenv",
   "language": "python",
   "name": "siberianpineenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
